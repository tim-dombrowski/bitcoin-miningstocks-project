---
title: "Bitcoin Mining Stock Analysis"
date: "Last updated: `r Sys.Date()`"
output: github_document
---

## Preliminary Work: Install/Load Packages

To try and ensure that this R Notebook will run successfully, we'll use the [renv package](https://cran.r-project.org/web/packages/renv/index.html) to create a project-specific library of packages. This will allow us to install the packages that we need for this project without affecting any other projects that we may be working on. Additionally, the project library will track the specific versions of the dependency packages so that any updates to those packages will not break this project.

The code chunk below will first install the renv package if it is not already installed. Then we will load the package. Next, we'll use the `restore()` function to install any packages listed in the renv.lock file. Once these packages are installed, we can load them into the R session using the `library()` commands. Below the code chunk, we'll list out the packages that will be used in the project demo. And if you run into any trouble using renv, then you can use the second code chunk below and that should be an even more reliable approach to install the required packages.

```{r setup, results='hide', message=FALSE}
# Install renv package if not already installed
if(!"renv" %in% installed.packages()[,"Package"]) install.packages("renv")
# Load renv package
library(renv)
# Use restore() to install any packages listed in the renv.lock file
renv::restore(clean=TRUE, lockfile="../renv.lock")
# Load in the packages
library(quantmod)
library(tidyverse)
library(tseries)
library(corrplot)
library(jsonlite)
library(stargazer)
```

* The [quantmod package](https://cran.r-project.org/package=quantmod) contains tools for importing and analyzing financial data.
* The [tidyverse package](https://www.tidyverse.org/) contains a suite of packages for data manipulation and visualization.
* The [tseries package](https://cran.r-project.org/package=tseries) contains additional time series analysis functions that we will explore.
* The [corrplot package](https://cran.r-project.org/package=corrplot) lets us create correlation plots.
* The [jsonlite package](https://cran.r-project.org/package=jsonlite) lets us more easily import JSON data.
* The [stargazer package](https://cran.r-project.org/package=stargazer) is used to generate formally typeset tables of regression results.
* The [rmarkdown package](https://cran.r-project.org/package=rmarkdown) is used to generate this R Notebook.

Since the rmarkdown functionality is built into RStudio, this last one is automatically loaded when you open RStudio. So no need to use the `library()` function for it. Another observation to make about the code chunk above is that it is labeled as `setup`, which is a special name, which the R Notebook will recognize and automatically run prior to running any other code chunk. This is useful for loading in packages and setting up other global options that will be used throughout the notebook. 

Then if you wish to try and update the versions of the various R packages in the lock file, you can use the `renv::update()` function to update the packages in the project library. However, it is possible that these updates could break the code in this notebook. If so, you may need to adapt the code to work with the updated packages.

My recommendation is to first run through the code using the versions of the packages in the lock file. Then if you want to try and update the packages, you can do so and then run through the code again to see if it still works. If not, you can always revert back to the lock file versions using the `renv::restore()` function.

If you update the packages and get everything working successfully, then you can update the lock file using the `renv::snapshot()` function. This will update the lock file with the versions of the packages that are currently installed in the project library. Then you can commit the updated lock file to the repository so that others can use the updated versions of the packages.

### Alternative Package Installation Code

If you run into any trouble using renv in the code chunk above, then you can use the code chunk below to install the required packages for this analysis. This method will first check if you have already installed the packages. If any are missing, it will then install them. Then it will load the packages into the R session. A potential flaw in this approach compared to using renv is that it will simply install the latest versions of the packages, which could potentially break some of the code in this notebook if any of the updates aren't backwards compatible. 

As long as you have downloaded the entire project repository, the renv chunk above will likely be managing the packages. Thus, the `eval=FALSE` option is used to prevent this chunk from running unless manually executed. So if you only downloaded this one Rmd file, this code chunk should take care of installing the packages for you.

```{r setup2, results='hide', message=FALSE, eval=FALSE}
# Create list of packages needed for this exercise
list.of.packages = c("quantmod","tidyverse","tseries","corrplot","jsonlite","stargazer","rmarkdown")
# Check if any have not yet been installed
new.packages = list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
# If any need to be installed, install them
if(length(new.packages)) install.packages(new.packages)
# Load in the packages
library(quantmod)
library(tidyverse)
library(tseries)
library(corrplot)
library(jsonlite)
library(stargazer)
```


## Data Import and Cleaning

First, let's use the `getSymbols()` function from the quantmod package to import the price data for several assets relevant to our analysis. In addition to the five mining stocks, we will also import the price data for Bitcoin and SPY to use as factors in explaining mining stock performance. Then we'll import data for inflation rates and treasury yields to compute real returns and risk premiums.

### Stock and Crypto Data

The `getSymbols()` function will automatically create an xts object for each asset with the OHLC (open, high, low, close) price series. The `src` argument specifies the source of the data, which in this case is Yahoo Finance. The `from` and `to` arguments specify the date range of the data to be imported. Although MARA stock goes back to mid-2012, the price series for BTC only goes back to late 2014. So we will pull all the daily stock data beginning in October 2014. For the other mining stocks, their series will begin when they first became publicly traded.

```{r assetdata, results='hide'}
startdate = "2014-10-01"
tickers = c("BTC-USD",
            "MARA",
            "CLSK",
            "RIOT",
            "CIFR",
            "HUT",
            "BTDR",
            "SPY")
getSymbols(tickers,
           src="yahoo",
           from=startdate,
           to=Sys.Date())
```

Next, we will convert the daily price data to monthly series using the `to.monthly()` function from the xts package. Although there could be some interesting analysis at the daily frequency, the monthly data will be more useful for analyzing long-term performance and volatility. Additionally, comparing daily data between bitcoin (which trades 365 days a year) and the stocks (which trade about 250 business days a year) can be misleading. So the monthly data will be more comparable across assets.

```{r assetcleaning}
BTCdaily = `BTC-USD`
BTCmonth = to.monthly(BTCdaily, name=NULL)
MARAdaily = MARA
MARAmonth = to.monthly(MARAdaily, name=NULL)
CLSKdaily = CLSK
CLSKmonth = to.monthly(CLSKdaily, name=NULL)
RIOTdaily = RIOT
RIOTmonth = to.monthly(RIOTdaily, name=NULL)
CIFRdaily = CIFR
CIFRmonth = to.monthly(CIFRdaily, name=NULL)
HUTdaily = HUT
HUTmonth = to.monthly(HUTdaily, name=NULL)
BTDRdaily = BTDR
BTDRmonth = to.monthly(BTDRdaily, name=NULL)
SPYdaily = SPY
SPYmonth = to.monthly(SPYdaily, name=NULL)
```

Now that we have each of the assets return series saved as daily and monthly series, let's compute the annualized returns for each. To do this, we can assume continuous compounding and use the log returns to calculate the annualized returns. If you compare the daily data for BTC and any of the stocks, you'll notice that BTC trades 365 days a year, while stock data typically is focused on the roughly 250 trading days per year. To try and resolve this discrepancy, we'll just annualize all of the daily returns using 365 days per year.

```{r assetreturns}
BTCdaily$Return = diff(log(BTCdaily$`BTC-USD.Adjusted`))*365*100
BTCmonth$Return = diff(log(BTCmonth$Adjusted))*12*100
MARAdaily$Return = diff(log(MARAdaily$MARA.Adjusted))*365*100 
MARAmonth$Return = diff(log(MARAmonth$Adjusted))*12*100
CLSKdaily$Return = diff(log(CLSKdaily$CLSK.Adjusted))*365*100
CLSKmonth$Return = diff(log(CLSKmonth$Adjusted))*12*100
RIOTdaily$Return = diff(log(RIOTdaily$RIOT.Adjusted))*365*100
RIOTmonth$Return = diff(log(RIOTmonth$Adjusted))*12*100
CIFRdaily$Return = diff(log(CIFRdaily$CIFR.Adjusted))*365*100
CIFRmonth$Return = diff(log(CIFRmonth$Adjusted))*12*100
HUTdaily$Return = diff(log(HUTdaily$HUT.Adjusted))*365*100
HUTmonth$Return = diff(log(HUTmonth$Adjusted))*12*100
BTDRdaily$Return = diff(log(BTDRdaily$BTDR.Adjusted))*365*100
BTDRmonth$Return = diff(log(BTDRmonth$Adjusted))*12*100
SPYdaily$Return = diff(log(SPYdaily$SPY.Adjusted))*365*100
SPYmonth$Return = diff(log(SPYmonth$Adjusted))*12*100
```

### Economic Data

Now let's collect some economic from [FRED](https://fred.stlouisfed.org/) to help with the analysis. We will import data for the Consumer Price Index (CPI) and the 10-year Treasury yield. The CPI data will be used to compute monthly inflation rates, and the 10-year Treasury yields will be used to represent the risk-free rate of return. Since we'll be imputing daily inflation rates using linear interpolation, let's start the import a month prior to the start of the stock data.

```{r econdata}
fredassets = c("CPIAUCSL","DGS10")
getSymbols(fredassets,
           src="FRED",
           from=as.character(as.Date(startdate) %m-% months(1)), 
           to=Sys.Date())
```

The specific CPI series we are using is the ["Consumer Price Index for All Urban Consumers: All Items" (CPIAUCSL).](https://fred.stlouisfed.org/series/CPIAUCSL), which is a common measure for inflation in the U.S. As with the stock price data, the CPI is an index for prices and tends to increase over time. This *non-stationarity* of the time series is addressed by converting to inflation measurements. See [bitcoin-timeseries-project](https://github.com/tim-dombrowski/bitcoin-timeseries-project) for more on this concept of time series stationarity.

Also, note that the CPI/inflation series is observed at a monthly frequency, rather than the daily frequency of the other data. So in the chunk below, we'll first compute annualized monthly inflation rates and then create a daily series that uses linear interpolation to fill in the missing values. This will allow us to merge the inflation data with the other daily data, even though the primary analysis and comparisons will focus on the monthly data.

```{r inflationcleaning}
# Compute the annualized inflation rate in percentage units
INFmonth = diff(log(CPIAUCSL))*12*100
# Create a daily xts object with the same length as the stock data
INFdaily = xts(order.by=seq(min(index(INFmonth)), length=nrow(BTCdaily), by="day"))
# Merge to monthly inflation observations
INFdaily = merge(INFdaily, INFmonth)
# Impute missing values using linear interpolation
INFdaily = na.approx(INFdaily, na.rm = FALSE)
```

Unlike the stock and CPI variables, which are measured in prices or index levels, the 10-year treasury yield is already an annualized rate in percentage units. So while we can use `to.monthly()` to convert the daily series into a monthly OHLC xts object, it'd be more appropriate to use the monthly average yield. This is done below using some tools from the dplyr and lubridate packages.

```{r dgs10cleaning}
# Generate monthly OHLC data for the 10-year treasury yield
DGS10daily = DGS10
DGS10month = to.monthly(DGS10daily, name=NULL)
# Aggregate to monthly frequency and compute means
DGS10dailydf = as.data.frame(DGS10daily)
DGS10dailydf$date = index(DGS10daily)
DGS10monthmean =  mutate(DGS10dailydf, date =floor_date(date,"month")) |> 
  group_by(date) |> summarise(DGS10 = mean(DGS10, na.rm=TRUE))
# Add the means to the monthly xts object
DGS10month$Mean = DGS10monthmean$DGS10
```

### Bitcoin Mining Data

Next, we'll use [mempool.space](https://mempool.space/) to collect data on Bitcoin mining difficulty and hashrate. The mining difficulty is a measure of how difficult it is to find a new block on the Bitcoin blockchain, while the hashrate is a measure of the total computational power of the Bitcoin network. Both of these variables can have an impact on the profitability of Bitcoin mining and the performance of Bitcoin mining stocks.

#### Hashrate Data

First, specify the API base and endpoint for the hashrate (see the [mempool.space API Documentation](https://mempool.space/docs/api/rest) for more details). Then make the API call and read the JSON response with the `fromJSON()` function from the jsonlite package.

```{r hashratedata}
# Build endpoint url for hashrates
mempoolbase = "https://mempool.space/api/v1/"
hashrateendpt = "mining/hashrate/pools/"
hashrateurl = paste(mempoolbase, hashrateendpt, sep="")
# Make API call and read JSON response
hashrateresponse = fromJSON(hashrateurl)
```

Next, we'll extract the hashrate and difficulty data from the JSON response and reformat the dates from Unix time to the R Date format. Then we'll convert the daily hashrate data to monthly data by calculating the average hashrate for each month.

```{r hashratecleaning}
# Extract hashrate table and difficulty table
hashratedf = hashrateresponse$hashrates
difficultydf = hashrateresponse$difficulty
# Reformat dates from unix time to R date
hashratedf$date = hashratedf$timestamp |> as.POSIXct() |> as.Date()
difficultydf$date = difficultydf$time |> as.POSIXct() |> as.Date()
# Convert daily hashrate data to monthly averages
hashratemonthdf =  mutate(hashratedf, date =floor_date(date,"month")) |> 
  group_by(date) |> summarise(avgHashrate = mean(avgHashrate, na.rm=TRUE))
```

Now that we have the hashrate data at both daily and monthly frequencies, let's focus a bit on the units. If we plot the hashrate data, we'll see that the units are in hashes per second. This quickly grows to a very large number, so it's common to see the hashrate expressed in terms of terahashes per second (TH/s), petahashes per second (PH/s), or exahashes per second (EH/s). See the values in the code chunk below for the scale of an exahash. *The warning generated by the log hashrate chart results from a few 0 observations in the data for the some of the earliest days in the Bitcoin network.*

```{r hashrateplot}
# Plot the hashrate data (daily in gray, monthly in black)
ggplot() +
  geom_line(aes(x=hashratedf$date, y=hashratedf$avgHashrate/1000000000000000000), color="darkgray") +
  geom_line(aes(x=hashratemonthdf$date, y=hashratemonthdf$avgHashrate/1000000000000000000), color="black") +
  labs(title="Bitcoin Network Hashrate (1 EH = 1,000,000,000,000,000,000 hashes)",
       x="Date",
       y="Hashrate (EH/s)")
# Log chart for the hashrate data (daily in gray, monthly in black)
ggplot() +
  geom_line(aes(x=hashratedf$date, y=hashratedf$avgHashrate), color="darkgray") +
  geom_line(aes(x=hashratemonthdf$date, y=hashratemonthdf$avgHashrate), color="black") +
  scale_y_continuous(transform='log10') +
  labs(title="Bitcoin Network Hashrate, log scale",
       x="Date",
       y="Hashrate (hashes/s)")
```

Since this data looks non-stationary, let's compute a differenced series. As with the stock series and economic data, we'll compute an annualized growth rate. Then we can validate this transformation by using the Augmented Dickey-Fuller test.

```{r hashrategrowth}
# Calculate daily hashrate growth and annualize it
hashratedf$annHashrateGrowth = c(NA, diff(log(hashratedf$avgHashrate))*365*100)
# Calculate monthly hashrate growth and annualize it
hashratemonthdf$annHashrateGrowth = c(NA, diff(log(hashratemonthdf$avgHashrate))*12*100)
```

To demonstrate non-stationarity of the hashrate series and stationarity of the growth rates, the Augmented Dickey-Fuller test will be used. The null hypothesis of the ADF test is that the series has a unit root, which implies that the series is non-stationary. If the p-value of the test is less than 0.05, then we can reject the null hypothesis and conclude that the series is stationary. Note the removal of the first 8 observations from the daily test, as the hashrate data in the first few days has some 0's, which produce some Inf and -Inf growth rates.

```{r hashrateadf}
adf.test(hashratedf$avgHashrate[-c(1:8)])
adf.test(hashratedf$annHashrateGrowth[-c(1:8)])
adf.test(hashratemonthdf$avgHashrate[-1])
adf.test(hashratemonthdf$annHashrateGrowth[-1])
```

After cleaning the hashrate data, let's reformat to an xts object and remove any observations prior to the start of the price series.

```{r hashrateclean}
# Preview first 10 rows of hash rate data
head(hashratedf, 10)
# Convert data frame to xts object
hashratexts = xts(hashratedf, order.by=hashratedf$date)
# Remove observations prior to startdate
hashratexts = hashratexts[paste0(as.character(startdate), "/")]
# Convert monthly data to xts object
hashratemonthxts = xts(hashratemonthdf, order.by=hashratemonthdf$date)
# Remove observations prior to startdate
hashratemonthxts = hashratemonthxts[paste0(as.character(startdate), "/")]
```

#### Difficulty Data

In addition to the hashrate data, the response from the mempool.space API includes the mining difficulty, which is a measure of how difficult it is to find a new block on the Bitcoin blockchain. The difficulty is adjusted every 2,016 blocks to ensure that the average time between blocks is approximately 10 minutes. The difficulty is a key factor in determining the profitability of Bitcoin mining, as it affects the amount of computational power required to mine new blocks.

Since the difficulty adjustment frequency is measured in blocks, this time series is much less uniform than the daily and monthly data for the other variables. To make the data more uniform, we'll fill the intermediate days with the last observed value. This is known as the last-observation-carried-forward method (`na.locf()`). Then we'll convert the daily difficulty data to monthly data by taking the average difficulty for each month and doing much of the same processing as was done for the hashrate data. See the comments in the code chunk for more details.

```{r difficultycleaning}
# Convert mining difficulty series to xts object
difficultyxts = xts(difficultydf, order.by=difficultydf$date)
# Create a daily xts object with the same length as the hashrate data
difficultydailyxts = xts(order.by=seq(min(difficultydf$date), length=length(hashratedf$date), by="day"))
# Merge the daily difficulty data with the daily hashrate data
difficultydailyxts = merge(difficultydailyxts, difficultyxts)
# Impute missing values using last-observation-carried-forward method
difficultydailyxts = na.locf(difficultydailyxts)
# Fix the date column
#difficultydailyxts = subset(difficultydailyxts, select=-date) 
difficultydailydf = data.frame(difficultydailyxts)
difficultydailydf$date = index(difficultydailyxts)
# Convert daily hashrate data to monthly averages
difficultymonthdf =  mutate(difficultydailydf, date=floor_date(date,"month")) |> 
  group_by(date) |> summarise(avgDifficulty=mean(difficulty, na.rm=TRUE))
# Plot the difficulty data (daily in gray, monthly in black)
ggplot() +
  geom_line(aes(x=difficultydailydf$date, y=difficultydailydf$difficulty), color="darkgray") +
  geom_line(aes(x=difficultymonthdf$date, y=difficultymonthdf$avgDifficulty), color="black") +
  labs(title="Bitcoin Network Difficulty",
       x="Date",
       y="Difficulty")
# Log chart for the hashrate data (daily in gray, monthly in black)
ggplot() +
  geom_line(aes(x=difficultydailydf$date, y=difficultydailydf$difficulty), color="darkgray") +
  geom_line(aes(x=difficultymonthdf$date, y=difficultymonthdf$avgDifficulty), color="black") +
  scale_y_continuous(transform='log10') +
  labs(title="Bitcoin Network Difficulty, log scale",
       x="Date",
       y="Difficulty")
# Compute difficulty growth rates
difficultydailydf$annDifficultyGrowth = c(NA, diff(log(difficultydailydf$difficulty))*365*100)
difficultymonthdf$annDifficultyGrowth = c(NA, diff(log(difficultymonthdf$avgDifficulty))*12*100)
# Estimate ADF tests
adf.test(difficultydailydf$difficulty[-c(1:8)])
adf.test(difficultydailydf$annDifficultyGrowth[-c(1:8)])
adf.test(difficultymonthdf$avgDifficulty[-1])
adf.test(difficultymonthdf$annDifficultyGrowth[-1])
# Convert monthly data to xts object
difficultymonthxts = xts(difficultymonthdf, order.by=difficultymonthdf$date)
# Add annDifficultyGrowth to daily xts object
difficultydailyxts$annDifficultyGrowth = xts(difficultydailydf$annDifficultyGrowth, order.by=index(difficultydailyxts))
# Remove observations prior to startdate
difficultydailyxts = difficultydailyxts[paste(as.character(startdate), "/", sep="")]
difficultymonthxts = difficultymonthxts[paste(as.character(startdate), "/", sep="")]
```

### Merge Final Dataset

Now that we have the annualized daily returns and annualized monthly returns, let's consolidate those values into a single data frame for each frequency. This will make it easier to analyze the data and create visualizations.

```{r finalmerges}
# Merge the daily returns into a single data frame
dailyreturns = merge(INFdaily$CPIAUCSL,
                     DGS10daily$DGS10,
                     BTCdaily$Return,
                     MARAdaily$Return,
                     CLSKdaily$Return,
                     RIOTdaily$Return,
                     CIFRdaily$Return,
                     HUTdaily$Return,
                     BTDRdaily$Return,
                     SPYdaily$Return,
                     hashratexts$annHashrateGrowth,
                     difficultydailyxts$annDifficultyGrowth)
colnames(dailyreturns) = c("INF","RF","BTC","MARA","CLSK","RIOT","CIFR","HUT","BTDR","SPY","Hashrate","Difficulty")
# Merge the monthly returns into a single data frame
monthlyreturns = merge(INFmonth$CPIAUCSL,
                       DGS10month$Mean,
                       BTCmonth$Return,
                       MARAmonth$Return,
                       CLSKmonth$Return,
                       RIOTmonth$Return,
                       CIFRmonth$Return,
                       HUTmonth$Return,
                       BTDRmonth$Return,
                       SPYmonth$Return,
                       hashratemonthxts$annHashrateGrowth,
                       difficultymonthxts$annDifficultyGrowth)
colnames(monthlyreturns) = c("INF","RF","BTC","MARA","CLSK","RIOT","CIFR","HUT","BTDR","SPY","Hashrate","Difficulty")
# Drop data prior to earliest inflation observation
dailyreturns = dailyreturns["2014-11-01/",]
monthlyreturns = monthlyreturns["2014-11-01/",]
# Trim any observations since the last inflation reading (typically 60-90 days)
ntrim = sum(is.na(tail(dailyreturns$INF,100)))
daily_nominal = dailyreturns[1:(nrow(dailyreturns)-ntrim),]
# Same for monthly series (typically 1-2 observations)
ntrim = sum(is.na(tail(monthlyreturns$INF)))
monthly_nominal = monthlyreturns[1:(nrow(monthlyreturns)-ntrim),]
```


## Data Analysis


### Real Returns

To compute the real returns for each asset, we will subtract the inflation rate from the nominal returns. This will allow us to analyze the performance of each asset after adjusting for inflation. We will compute the real returns for both the daily and monthly return series.

```{r realreturns}
infadjust = function(nominal, inf) {
  return((nominal-inf)/(1+(inf/100)))
}
# Compute real returns for daily series
daily_real = daily_nominal[,-1] # drop INF column since it is used here
daily_real$RF = infadjust(daily_nominal$RF, daily_nominal$INF)
daily_real$BTC = infadjust(daily_nominal$BTC, daily_nominal$INF)
daily_real$MARA = infadjust(daily_nominal$MARA, daily_nominal$INF)
daily_real$CLSK = infadjust(daily_nominal$CLSK, daily_nominal$INF)
daily_real$RIOT = infadjust(daily_nominal$RIOT, daily_nominal$INF)
daily_real$CIFR = infadjust(daily_nominal$CIFR, daily_nominal$INF)
daily_real$HUT = infadjust(daily_nominal$HUT, daily_nominal$INF)
daily_real$BTDR = infadjust(daily_nominal$BTDR, daily_nominal$INF)
daily_real$SPY = infadjust(daily_nominal$SPY, daily_nominal$INF)
# Compute real returns for monthly series
monthly_real = monthly_nominal[,-1] # drop INF column since it is used here
monthly_real$RF = infadjust(monthly_nominal$RF, monthly_nominal$INF)
monthly_real$BTC = infadjust(monthly_nominal$BTC, monthly_nominal$INF)
monthly_real$MARA = infadjust(monthly_nominal$MARA, monthly_nominal$INF)
monthly_real$CLSK = infadjust(monthly_nominal$CLSK, monthly_nominal$INF)
monthly_real$RIOT = infadjust(monthly_nominal$RIOT, monthly_nominal$INF)
monthly_real$CIFR = infadjust(monthly_nominal$CIFR, monthly_nominal$INF)
monthly_real$HUT = infadjust(monthly_nominal$HUT, monthly_nominal$INF)
monthly_real$BTDR = infadjust(monthly_nominal$BTDR, monthly_nominal$INF)
monthly_real$SPY = infadjust(monthly_nominal$SPY, monthly_nominal$INF)
```

### Excess Returns (Risk Premiums)

To compute the excess returns for each asset, we will subtract the risk-free rate of return from the real returns. This will allow us to analyze the performance of each asset after adjusting for inflation and the risk-free rate. We will compute the excess returns for both the daily and monthly return series.

```{r excessreturns}
# Compute excess returns for daily series
daily_excess = daily_real[,-1] # drop RF column since it is used here
daily_excess$BTC = daily_real$BTC - daily_real$RF
daily_excess$MARA = daily_real$MARA - daily_real$RF
daily_excess$CLSK = daily_real$CLSK - daily_real$RF
daily_excess$RIOT = daily_real$RIOT - daily_real$RF
daily_excess$CIFR = daily_real$CIFR - daily_real$RF
daily_excess$HUT = daily_real$HUT - daily_real$RF
daily_excess$BTDR = daily_real$BTDR - daily_real$RF
daily_excess$SPY = daily_real$SPY - daily_real$RF
# Compute excess returns for monthly series
monthly_excess = monthly_real[,-1] # drop RF column since it is used here
monthly_excess$BTC = monthly_real$BTC - monthly_real$RF
monthly_excess$MARA = monthly_real$MARA - monthly_real$RF
monthly_excess$CLSK = monthly_real$CLSK - monthly_real$RF
monthly_excess$RIOT = monthly_real$RIOT - monthly_real$RF
monthly_excess$CIFR = monthly_real$CIFR - monthly_real$RF
monthly_excess$HUT = monthly_real$HUT - monthly_real$RF
monthly_excess$BTDR = monthly_real$BTDR - monthly_real$RF
monthly_excess$SPY = monthly_real$SPY - monthly_real$RF
```

### Univariate Statistics

We will start by calculating the average annual returns and standard deviations for each series. The chunk below focuses on the daily returns. First, we'll compute the average annualized nominal returns, real returns, and excess returns for each asset. Then we'll compute the standard deviation of the annual returns for each asset. We'll do the same for the monthly returns in the next chunk.

```{r meansddaily}
# Compute the average annualized nominal returns
colMeans(daily_nominal, na.rm=TRUE) |> round(2)
# Compute the average annualized real returns
colMeans(daily_real, na.rm=TRUE) |> round(2)
# Compute the average annualized excess returns
colMeans(daily_excess, na.rm=TRUE) |> round(2)
# Compute the standard deviation of the annual nominal returns
apply(daily_nominal, 2, sd, na.rm=TRUE) |> round(2)
# Compute the standard deviation of the annual real returns
apply(daily_real, 2, sd, na.rm=TRUE) |> round(2)
# Compute the standard deviation of the annual excess returns
apply(daily_excess, 2, sd, na.rm=TRUE) |> round(2)
```

Now at the monthly frequency:

```{r meansdmonthly}
# Compute the average annualized nominal returns
colMeans(monthly_nominal, na.rm=TRUE) |> round(2)
# Compute the average annualized real returns
colMeans(monthly_real, na.rm=TRUE) |> round(2)
# Compute the average annualized excess returns
colMeans(monthly_excess, na.rm=TRUE) |> round(2)
# Compute the standard deviation of the annual nominal returns
apply(monthly_nominal, 2, sd, na.rm=TRUE) |> round(2)
# Compute the standard deviation of the annual real returns
apply(monthly_real, 2, sd, na.rm=TRUE) |> round(2)
# Compute the standard deviation of the annual excess returns
apply(monthly_excess, 2, sd, na.rm=TRUE) |> round(2)
```

However, an important note to make about the results above is that only BTC, MARA, and SPY have data going back to 2014. So the other mining stocks each have shorter time frames. Thus, we should be cautious to draw any comparative conclusions from the stats above.

### Subset to Final Datasets

To create a more comparable basis for analysis, let's create a subset of the monthly series that only includes observations where all assets have data. 

```{r subsetdata}
# Subset down to complete.cases
monthly_nominal_final = monthly_nominal[complete.cases(monthly_nominal),]
monthly_real_final = monthly_real[complete.cases(monthly_real),]
monthly_excess_final = monthly_excess[complete.cases(monthly_excess),]
```

Now let's re-run the univariate statistics for the final subset of monthly data.

```{r meansdmonthlyfinal}
# Compute the average annualized nominal returns
colMeans(monthly_nominal_final, na.rm=TRUE) |> round(2)
# Compute the average annualized real returns
colMeans(monthly_real_final, na.rm=TRUE) |> round(2)
# Compute the average annualized excess returns
colMeans(monthly_excess_final, na.rm=TRUE) |> round(2)
# Compute the standard deviation of the annual nominal returns
apply(monthly_nominal_final, 2, sd, na.rm=TRUE) |> round(2)
# Compute the standard deviation of the annual real returns
apply(monthly_real_final, 2, sd, na.rm=TRUE) |> round(2)
# Compute the standard deviation of the annual excess returns
apply(monthly_excess_final, 2, sd, na.rm=TRUE) |> round(2)
```

Since we have the excess returns, we can quite easily calculate Sharpe ratios for each asset to compare risk-adjusted returns. The Sharpe ratio is calculated as the average excess return divided by the standard deviation of the excess returns. The higher the Sharpe ratio, the better the risk-adjusted return.

```{r sharpes}
# Compute the Sharpe ratios for the monthly excess returns
sharpe = colMeans(monthly_excess_final, na.rm=TRUE)/apply(monthly_excess_final, 2, sd, na.rm=TRUE)
sharpe |> round(4)
```

### Multivariate Statistics

Now let's explore the relationships between the variables in our cleaned dataset. For each frequency, we'll generate a correlation matrix and a correlation plot to visualize the relationships between the assets.

#### Correlations

Since the transformations from nominal to real and excess returns are linear, the correlations remain the same. So for the daily data, we'll compute the correlation matrix for the nominal returns and then create a correlation plot. *Note the use of the `use="pairwise.complete"` argument in the `cor()` function to handle missing values in the data, and the use of the `|>` operator to round the answers to two decimal places.*

```{r corrsdaily}
# Compute the correlation matrix for the daily returns
cor(daily_nominal, use="pairwise.complete") |> round(2)
# Create a correlation plot for the daily returns
corrplot(cor(daily_nominal, use="pairwise.complete"), method="color")
```

Now for the monthly data, we'll start with the full dataset using the `pairwise.complete` option for handling the missing values.

```{r corrsmonthlyfull}
# Compute the correlation matrix for the full monthly returns
cor(monthly_nominal, use="pairwise.complete") |> round(2)
# Create a correlation plot for the full monthly returns
corrplot(cor(monthly_nominal, use="pairwise.complete"), method="color")
```

Then we'll create a correlation matrix and plot for the subset with no missing values.

```{r corrsmonthly}
# Compute the correlation matrix for the full monthly returns
cor(monthly_nominal_final) |> round(2)
# Create a correlation plot for the full monthly returns
corrplot(cor(monthly_nominal_final), method="color")
```

### Factor Models

#### Captial Asset Pricing Model (CAPM)

Let's start by applying CAPM to each of the mining stocks and BTC. See the [sharpe-ratio-project](https://github.com/tim-dombrowski/sharpe-ratio-project) for a more focused analysis on the CAPM model. From this point on, we'll stick to the final monthly subset of data spanning August 2021 to present.

```{r capm}
# BTC CAPM Regression
CAPM_BTC = lm(BTC~SPY, data=monthly_nominal_final)
summary(CAPM_BTC)
# MARA CAPM Regression
CAPM_MARA = lm(MARA~SPY, data=monthly_nominal_final)
summary(CAPM_MARA)
# CLSK CAPM Regression
CAPM_CLSK = lm(CLSK~SPY, data=monthly_nominal_final)
summary(CAPM_CLSK)
# RIOT CAPM Regression
CAPM_RIOT = lm(RIOT~SPY, data=monthly_nominal_final)
summary(CAPM_RIOT)
# CIFR CAPM Regression
CAPM_CIFR = lm(CIFR~SPY, data=monthly_nominal_final)
summary(CAPM_CIFR)
# HUT CAPM Regression
CAPM_HUT = lm(HUT~SPY, data=monthly_nominal_final)
summary(CAPM_HUT)
# BTDR CAPM Regression
CAPM_BTDR = lm(BTDR~SPY, data=monthly_nominal_final)
summary(CAPM_BTDR)
```

Now let's extract the residuals from those regressions and look at those correlations.

```{r capmresiduals}
# Extract residuals from CAPM regressions
CAPM_resids = data.frame(
  BTC = residuals(CAPM_BTC),
  MARA = residuals(CAPM_MARA),
  CLSK = residuals(CAPM_CLSK),
  RIOT = residuals(CAPM_RIOT),
  CIFR = residuals(CAPM_CIFR),
  HUT = residuals(CAPM_HUT),
  BTDR = residuals(CAPM_BTDR)
)
# Compute the correlation matrix for the residuals
cor(CAPM_resids) |> round(2)
# Create a correlation plot for the residuals
corrplot(cor(CAPM_resids), method="color")
```


#### BTC-Factor Model (BFM)

Next, we'll use the BTC excess return as a second factor for the mining stock regressions. This will allow us to remove the common risk factor of BTC and analyze any remaining correlations between the mining stocks. 

```{r bfm}
# BTC-Factor Model Regressions
BFM_MARA = lm(MARA~SPY+BTC, data=monthly_nominal_final)
summary(BFM_MARA)
BFM_CLSK = lm(CLSK~SPY+BTC, data=monthly_nominal_final)
summary(BFM_CLSK)
BFM_RIOT = lm(RIOT~SPY+BTC, data=monthly_nominal_final)
summary(BFM_RIOT)
BFM_CIFR = lm(CIFR~SPY+BTC, data=monthly_nominal_final)
summary(BFM_CIFR)
BFM_HUT = lm(HUT~SPY+BTC, data=monthly_nominal_final)
summary(BFM_HUT)
BFM_BTDR = lm(BTDR~SPY+BTC, data=monthly_nominal_final)
summary(BFM_BTDR)
```

Now let's extract the residuals from those regressions and look at those correlations.

```{r bfmresiduals}
# Extract residuals from BFM regressions
BFM_resids = data.frame(
  MARA = residuals(BFM_MARA),
  CLSK = residuals(BFM_CLSK),
  RIOT = residuals(BFM_RIOT),
  CIFR = residuals(BFM_CIFR),
  HUT = residuals(BFM_HUT),
  BTDR = residuals(BFM_BTDR)
)
# Compute the correlation matrix for the residuals
cor(BFM_resids) |> round(2)
# Create a correlation plot for the residuals
corrplot(cor(BFM_resids), method="color")
```

#### Hashrate-Factor Models

Now let's add the annualized hashrate growth as a third factor to the mining stock regressions. This will allow us to analyze the impact of the hashrate on the mining stocks.

```{r hfm}
# Hashrate-Factor Model Regressions
HFM_MARA = lm(MARA~SPY+BTC+Hashrate, data=monthly_nominal_final)
summary(HFM_MARA)
HFM_CLSK = lm(CLSK~SPY+BTC+Hashrate, data=monthly_nominal_final)
summary(HFM_CLSK)
HFM_RIOT = lm(RIOT~SPY+BTC+Hashrate, data=monthly_nominal_final)
summary(HFM_RIOT)
HFM_CIFR = lm(CIFR~SPY+BTC+Hashrate, data=monthly_nominal_final)
summary(HFM_CIFR)
HFM_HUT = lm(HUT~SPY+BTC+Hashrate, data=monthly_nominal_final)
summary(HFM_HUT)
HFM_BTDR = lm(BTDR~SPY+BTC+Hashrate, data=monthly_nominal_final)
summary(HFM_BTDR)
```

Since that doesn't seem to add much explanatory power to any of those models, let's just skip those residuals and correlations.

#### Difficulty-Factor Models

Lastly, let's see if the mining difficulty can be more effectively than the hashrate growth as a third factor. Most likely not since the difficulty has a very high correlation with the hashrate. But we can check anyway.

```{r dfm}
# Difficulty-Factor Model Regressions
DFM_MARA = lm(MARA~SPY+BTC+Difficulty, data=monthly_nominal_final)
summary(DFM_MARA)
DFM_CLSK = lm(CLSK~SPY+BTC+Difficulty, data=monthly_nominal_final)
summary(DFM_CLSK)
DFM_RIOT = lm(RIOT~SPY+BTC+Difficulty, data=monthly_nominal_final)
summary(DFM_RIOT)
DFM_CIFR = lm(CIFR~SPY+BTC+Difficulty, data=monthly_nominal_final)
summary(DFM_CIFR)
DFM_HUT = lm(HUT~SPY+BTC+Difficulty, data=monthly_nominal_final)
summary(DFM_HUT)
DFM_BTDR = lm(BTDR~SPY+BTC+Difficulty, data=monthly_nominal_final)
summary(DFM_BTDR)
```

As expected, those don't add much explanatory power either. So let's skip the residuals and correlations again.

#### Four-Factor Model

Lastly, let's see if the four-factor model (SPY, BTC, Hashrate, Difficulty) can provide a better fit for the mining stocks.

```{r ffm}
# Four-Factor Model Regressions
FFM_MARA = lm(MARA~SPY+BTC+Hashrate+Difficulty, data=monthly_nominal_final)
summary(FFM_MARA)
FFM_CLSK = lm(CLSK~SPY+BTC+Hashrate+Difficulty, data=monthly_nominal_final)
summary(FFM_CLSK)
FFM_RIOT = lm(RIOT~SPY+BTC+Hashrate+Difficulty, data=monthly_nominal_final)
summary(FFM_RIOT)
FFM_CIFR = lm(CIFR~SPY+BTC+Hashrate+Difficulty, data=monthly_nominal_final)
summary(FFM_CIFR)
FFM_HUT = lm(HUT~SPY+BTC+Hashrate+Difficulty, data=monthly_nominal_final)
summary(FFM_HUT)
FFM_BTDR = lm(BTDR~SPY+BTC+Hashrate+Difficulty, data=monthly_nominal_final)
summary(FFM_BTDR)
```


## Generating Summaries by Stock

To package up our results in a more digestible format, let's create some nicely formatted tables using the stargazer package. This package lets us output some nice text-based tables here in the R output, but also can generate LaTeX code for inclusion in a more formal report or presentation. See below for examples of both applications. These will generate the .tex files in the Figures folder. Then you can compile the Tables.tex file to generate Tables.pdf with the formally typeset tables.

### Summary Statistics

Let's start by generating summary statistics for the final monthly dataset. We'll generate summary statistics for the nominal returns, real returns, and excess returns. These tables will include the mean, standard deviation, minimum, 25th percentile, median, 75th percentile, and maximum values for each asset.

```{r sumstats_nominal}
# Generate summary statistics for the final nominal returns
stargazer(monthly_nominal_final, 
          summary=TRUE, 
          type='text',
          align=TRUE,
          digits=2)
# Generate and save output to a LaTeX file
stargazer(monthly_nominal_final, 
          summary=TRUE,
          type='latex',
          align=TRUE,
          digits=2, 
          font.size="large",
          out="Figures/SummaryStats_nominal.tex",
          title="Summary Statistics for the Final Monthly Dataset. Asset nominal returns and growth rates are all annualized and measured in percentage units. Table generated with the stargazer R package (Hlavac, 2022).", 
          label="SummaryStats_nominal")
```

```{r sumstats_real}
# Generate summary statistics for the final real returns
stargazer(monthly_real_final, 
          summary=TRUE, 
          type='text',
          align=TRUE,
          digits=2)
# Generate and save output to a LaTeX file
stargazer(monthly_real_final, 
          summary=TRUE,
          type='latex',
          align=TRUE,
          digits=2, 
          font.size="large",
          out="Figures/SummaryStats_real.tex",
          title="Summary Statistics for the Final Monthly Dataset. Asset real returns and growth rates are all annualized and measured in percentage units. Table generated with the stargazer R package (Hlavac, 2022).", 
          label="SummaryStats_real")
```

```{r sumstats_excess}
# Generate summary statistics for the final real returns
stargazer(monthly_excess_final, 
          summary=TRUE, 
          type='text',
          align=TRUE,
          digits=2)
# Generate and save output to a LaTeX file
stargazer(monthly_excess_final, 
          summary=TRUE,
          type='latex',
          align=TRUE,
          digits=2, 
          font.size="large",
          out="Figures/SummaryStats_excess.tex",
          title="Summary Statistics for the Final Monthly Dataset. Asset excess returns and growth rates are all annualized and measured in percentage units. Table generated with the stargazer R package (Hlavac, 2022).", 
          label="SummaryStats_excess")
```

### Model Results by Company

Now let's generate tables for the model results for each of the mining stocks. These tables will include the coefficients, standard errors, t-statistics, and p-values for each factor in the model. After aggregating the model results for each stock, we can omit residual standard errors and F-statistics from the tables to keep them concise.

```{r MARAmodels}
# Generate summary statistics for the final real returns
stargazer(CAPM_MARA, BFM_MARA, HFM_MARA, DFM_MARA, FFM_MARA, 
          type='text',
          align=TRUE,
          digits=2,
          omit.stat=c("ser","f"))
# Generate and save output to a LaTeX file
stargazer(CAPM_MARA, BFM_MARA, HFM_MARA, DFM_MARA, FFM_MARA, 
          type='latex',
          align=TRUE,
          digits=2, 
          font.size="large",
          out="Figures/ModelResults_MARA.tex",
          title="Factor Model Results for Marathon Digital Holdings (MARA). Table generated with the stargazer R package (Hlavac, 2022).", 
          label="ModelResults_MARA",
          omit.stat=c("ser","f"))
```

```{r CLSKmodels}
# Generate summary statistics for the final real returns
stargazer(CAPM_CLSK, BFM_CLSK, HFM_CLSK, DFM_CLSK, FFM_CLSK, 
          type='text',
          align=TRUE,
          digits=2,
          omit.stat=c("ser","f"))
# Generate and save output to a LaTeX file
stargazer(CAPM_CLSK, BFM_CLSK, HFM_CLSK, DFM_CLSK, FFM_CLSK, 
          type='latex',
          align=TRUE,
          digits=2, 
          font.size="large",
          out="Figures/ModelResults_CLSK.tex",
          title="Factor Model Results for Cleanspark (CLSK). Table generated with the stargazer R package (Hlavac, 2022).", 
          label="ModelResults_CLSK",
          omit.stat=c("ser","f"))
```

```{r RIOTmodels}
# Generate summary statistics for the final real returns
stargazer(CAPM_RIOT, BFM_RIOT, HFM_RIOT, DFM_RIOT, FFM_RIOT, 
          type='text',
          align=TRUE,
          digits=2,
          omit.stat=c("ser","f"))
# Generate and save output to a LaTeX file
stargazer(CAPM_RIOT, BFM_RIOT, HFM_RIOT, DFM_RIOT, FFM_RIOT, 
          type='latex',
          align=TRUE,
          digits=2, 
          font.size="large",
          out="Figures/ModelResults_RIOT.tex",
          title="Factor Model Results for Riot Blockchain (RIOT). Table generated with the stargazer R package (Hlavac, 2022).", 
          label="ModelResults_RIOT",
          omit.stat=c("ser","f"))
```

```{r CIFRmodels}
# Generate summary statistics for the final real returns
stargazer(CAPM_CIFR, BFM_CIFR, HFM_CIFR, DFM_CIFR, FFM_CIFR, 
          type='text',
          align=TRUE,
          digits=2,
          omit.stat=c("ser","f"))
# Generate and save output to a LaTeX file
stargazer(CAPM_CIFR, BFM_CIFR, HFM_CIFR, DFM_CIFR, FFM_CIFR, 
          type='latex',
          align=TRUE,
          digits=2, 
          font.size="large",
          out="Figures/ModelResults_CIFR.tex",
          title="Factor Model Results for Cipher Mining (CIFR). Table generated with the stargazer R package (Hlavac, 2022).", 
          label="ModelResults_CIFR",
          omit.stat=c("ser","f"))
```

```{r HUTmodels}
# Generate summary statistics for the final real returns
stargazer(CAPM_HUT, BFM_HUT, HFM_HUT, DFM_HUT, FFM_HUT, 
          type='text',
          align=TRUE,
          digits=2,
          omit.stat=c("ser","f"))
# Generate and save output to a LaTeX file
stargazer(CAPM_HUT, BFM_HUT, HFM_HUT, DFM_HUT, FFM_HUT, 
          type='latex',
          align=TRUE,
          digits=2, 
          font.size="large",
          out="Figures/ModelResults_HUT.tex",
          title="Factor Model Results for Hut 8 Mining (HUT). Table generated with the stargazer R package (Hlavac, 2022).", 
          label="ModelResults_HUT",
          omit.stat=c("ser","f"))
```

```{r BTDRmodels}
# Generate summary statistics for the final real returns
stargazer(CAPM_BTDR, BFM_BTDR, HFM_BTDR, DFM_BTDR, FFM_BTDR, 
          type='text',
          align=TRUE,
          digits=2,
          omit.stat=c("ser","f"))
# Generate and save output to a LaTeX file
stargazer(CAPM_BTDR, BFM_BTDR, HFM_BTDR, DFM_BTDR, FFM_BTDR, 
          type='latex',
          align=TRUE,
          digits=2, 
          font.size="large",
          out="Figures/ModelResults_BTDR.tex",
          title="Factor Model Results for Bitdeer (BTDR). Table generated with the stargazer R package (Hlavac, 2022).", 
          label="ModelResults_BTDR",
          omit.stat=c("ser","f"))
```

